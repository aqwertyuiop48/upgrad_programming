{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3c1a5b3a",
      "metadata": {
        "id": "3c1a5b3a"
      },
      "source": [
        "<pre>\n",
        "1.\n",
        "Using the rule/frequency-based PoS tagger (which you can build with the training data set provided above), you can find out the PoS tag for each word.\n",
        "What will be the PoS tag for the word ‘saw’ in this sentence?\n",
        "\n",
        "S: “I saw him running away”.\n",
        "\n",
        "(Ignore the case of the text in the sentence as well as in your training data).\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2a3c6df0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a3c6df0",
        "outputId": "6950bd9f-4198-440f-c48a-753ddc1f9109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('I', 'PRON')\n",
            "('saw', 'VERB')\n",
            "('him', 'PRON')\n",
            "('running', 'VERB')\n",
            "('away', 'ADV')\n",
            "tag\n",
            "VERB    347\n",
            "NOUN      5\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/aqwertyuiop48/upgrad_programming/refs/heads/main/2_Course_continuation/_3_NLP/_2_Syntactic_processing/_1_Intro_to_Syntactic_processing_and_POS_tagging/tagged_words.csv\")\n",
        "sent = \"I saw him running away\"\n",
        "\n",
        "def get_common_tag(data,word):\n",
        "    if word.lower() in data['word'].unique():\n",
        "        q = f\"word=='{word.lower()}'\"\n",
        "        return word , data.query(q)['tag'].value_counts().head(1).index.tolist()[0]\n",
        "    else:\n",
        "        return f\"{word} not in data\"\n",
        "\n",
        "for word in sent.split(\" \"):\n",
        "    print(get_common_tag(data,word))\n",
        "\n",
        "print(\n",
        "    data.query(\"word=='saw'\")['tag'].value_counts()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00a84a5f",
      "metadata": {
        "id": "00a84a5f"
      },
      "source": [
        "<hr>\n",
        "<pre>\n",
        "\n",
        "2.\n",
        "You can use the rule/frequency-based PoS tagger (which you can build with the training data set provided above) to find out the PoS tag for each word of any sentence.\n",
        "\n",
        "Now, use this data set to create PoS tags for the sentence “He wished he was rich”. (Ignore the case of the words in the sentence as well as in the training data). Match the words in the left column with their PoS tags in the column on the right.\n",
        "\n",
        "\n",
        "\n",
        "1. He\ta. VERB\n",
        "2. wished\tb. ADJ\n",
        "3. he\tc. PRON\n",
        "4. was\td. NOUN\n",
        "5. rich\te. ADP\n",
        "<pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8612abb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8612abb5",
        "outputId": "fa5c7acf-f195-4c17-d1b2-fa27045f7ddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('He', 'PRON')\n",
            "('wished', 'VERB')\n",
            "('he', 'PRON')\n",
            "('was', 'VERB')\n",
            "('rich', 'ADJ')\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/aqwertyuiop48/upgrad_programming/refs/heads/main/2_Course_continuation/_3_NLP/_2_Syntactic_processing/_1_Intro_to_Syntactic_processing_and_POS_tagging/tagged_words.csv\")\n",
        "s = \"He wished he was rich\"\n",
        "\n",
        "def get_common_tag(data,word):\n",
        "    if word.lower() in data['word'].unique():\n",
        "        q = f\"word=='{word.lower()}'\"\n",
        "        return word , data.query(q)['tag'].value_counts().head(1).index.tolist()[0]\n",
        "    else:\n",
        "        return f\"{word} not in data\"\n",
        "\n",
        "for word in s.split(\" \"):\n",
        "    print(get_common_tag(data,word))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b994cc8",
      "metadata": {
        "id": "7b994cc8"
      },
      "source": [
        "<hr>\n",
        "<pre>\n",
        "3.\n",
        "You are already aware of how an emission matrix looks. Now, take a look at this emission matrix.\n",
        "\n",
        "\n",
        "WORDS\tPOS TAG_1\tPOS TAG_2\tPOS TAG_3\n",
        "word_1\t0.25\t0.31\t0.12\n",
        "word_2\t0.054\t0.10\t0.08\n",
        "word_3\t0.15\t0.09\t0.32\n",
        "...\t...\t...\t...\n",
        "You already know that the column-wise sum of an emission matrix is always 1. So, in the matrix above, suppose the word ‘word_1’ appears a total of 20 times as a ‘PoS_TAG_1’ in the entire data set, and the total count of ‘PoS_TAG_1’ in the entire data set is 80. Then the emission probability of ‘word_1’ will be 20/80, i.e., 0.25, which is also referred to as P(word_1| PoS_TAG_1).\n",
        "\n",
        "Now, based on the knowledge of the emission matrix and probability, you need to create an emission matrix for the given data set, i.e., ‘tagged_words.csv’. You can ignore the case of the words in the data set. What is the value of P(his|PRON)?\n",
        "\n",
        "Hint: You can use the Pandas library and try to create a crosstab using pd.crosstab() and use the normalize option for the columns to obtain the proportion values appropriately.\n",
        "\n",
        "\n",
        "\n",
        "Note: You need to round off the final answer up to 3 decimal places to get the correct option. You can use the 'round()' function in python.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8365cffd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8365cffd",
        "outputId": "7668e6de-711f-4417-e077-4f70b5dfdb10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.001)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/aqwertyuiop48/upgrad_programming/refs/heads/main/2_Course_continuation/_3_NLP/_2_Syntactic_processing/_1_Intro_to_Syntactic_processing_and_POS_tagging/tagged_words.csv\")\n",
        "emmission_matrix = pd.crosstab(data['word'],data['tag'],normalize='columns')\n",
        "\n",
        "word = 'his'\n",
        "emmission_matrix.loc[word][emmission_matrix.loc[word]>0].round(3)\n",
        "emmission_matrix['PRON'].loc['his'].round(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "495c9041",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "495c9041",
        "outputId": "f2923b4b-7b90-4442-bac0-21ae0c1995b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Time in IST: 2025-11-13 23:43:41\n"
          ]
        }
      ],
      "source": [
        "import datetime, pytz;\n",
        "print(\"Current Time in IST:\", datetime.datetime.now(pytz.utc).astimezone(pytz.timezone('Asia/Kolkata')).strftime('%Y-%m-%d %H:%M:%S'))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}